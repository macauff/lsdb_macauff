{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data\n",
    "\n",
    "Script to generate test data for lsdb_macauff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from macauff.utils import generate_random_catalogs\n",
    "\n",
    "import hipscat_import.pipeline as runner\n",
    "from hipscat_import.catalog.arguments import ImportArguments\n",
    "import tempfile\n",
    "from dask.distributed import Client\n",
    "\n",
    "tmp_path = tempfile.TemporaryDirectory()\n",
    "tmp_dir = tmp_path.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic \"catalog a\", \"catalog b\"\n",
    "\n",
    "We create two catalogs, \"catalog a\" and \"catalog b\", with some known counterpart pairings. This is useful to confirm that the crossmatch routine returns the same known counterparts.\n",
    "\n",
    "This is largely copy-pasted from macauff/src/macauff/utils.py\n",
    "\n",
    "Modifications are made to::\n",
    "\n",
    "- construct a single dataframe using the randomly generated data\n",
    "- construct string identifiers for each object in each catalog\n",
    "- write out to one CSV per catalog, and one for counterpart IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_a_source, num_b_source, num_common = 50, 100, 40\n",
    "extent = [0, 0.25, 50, 50.3]\n",
    "num_filters_a, num_filters_b = 3, 2\n",
    "a_uncert, b_uncert = 0.1, 0.3\n",
    "(\n",
    "    a_astro,\n",
    "    b_astro,\n",
    "    a_photo,\n",
    "    b_photo,\n",
    "    amagref,\n",
    "    bmagref,\n",
    "    a_pair_indices,\n",
    "    b_pair_indices,\n",
    ") = generate_random_catalogs(\n",
    "    num_a_source,\n",
    "    num_b_source,\n",
    "    num_common,\n",
    "    extent,\n",
    "    num_filters_a,\n",
    "    num_filters_b,\n",
    "    a_uncert,\n",
    "    b_uncert,\n",
    "    seed=5732,\n",
    ")\n",
    "\n",
    "## Make a pretty CSV of catalog A\n",
    "cat_a_ids = [f\"cat_a_3{index :03d}\" for index in np.arange(num_a_source)]\n",
    "\n",
    "cat_a_data = {\n",
    "    \"survey_id\": cat_a_ids,\n",
    "    \"ra\": a_astro[:, 0],\n",
    "    \"dec\": a_astro[:, 1],\n",
    "    \"astro_unc\": a_astro[:, 2],\n",
    "}\n",
    "for index in range(num_filters_a):\n",
    "    cat_a_data[f\"filter_{index}\"] = a_photo[:, index]\n",
    "cat_a_data[\"magref\"] = amagref\n",
    "catalog_a_frame = pd.DataFrame(cat_a_data)\n",
    "\n",
    "catalog_a_frame.to_csv(\"catalog_a.csv\", index=False)\n",
    "\n",
    "## Make a pretty CSV of catalog B\n",
    "cat_b_ids = [f\"cat_b_8{index :03d}\" for index in np.arange(num_b_source)]\n",
    "\n",
    "cat_b_data = {\n",
    "    \"survey_id\": cat_b_ids,\n",
    "    \"ra\": b_astro[:, 0],\n",
    "    \"dec\": b_astro[:, 1],\n",
    "    \"astro_unc\": b_astro[:, 2],\n",
    "}\n",
    "for index in range(num_filters_b):\n",
    "    cat_b_data[f\"filter_{index}\"] = b_photo[:, index]\n",
    "cat_b_data[\"magref\"] = bmagref\n",
    "catalog_b_frame = pd.DataFrame(cat_b_data)\n",
    "\n",
    "catalog_b_frame.to_csv(\"catalog_b.csv\", index=False)\n",
    "\n",
    "## Make a pretty CSV of counterparts\n",
    "counters = {\n",
    "    \"cat_a\": [f\"cat_a_3{index :03d}\" for index in a_pair_indices],\n",
    "    \"cat_b\": [f\"cat_b_8{index :03d}\" for index in b_pair_indices],\n",
    "}\n",
    "pd.DataFrame(counters).to_csv(\"counters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pipeline catalogs\n",
    "\n",
    "Using the two above generic catalogs, we want to import the known matches as an association table.\n",
    "\n",
    "The below steps will convert the catalog CSV files into hipscat catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_a_args = ImportArguments(\n",
    "    input_file_list=[\"catalog_a.csv\"],\n",
    "    output_path=\"import_pipeline\",\n",
    "    sort_columns=\"survey_id\",\n",
    "    constant_healpix_order=4,\n",
    "    file_reader=\"csv\",\n",
    "    output_artifact_name=\"catalog_a\",\n",
    "    tmp_dir=tmp_dir,\n",
    ")\n",
    "catalog_b_args = ImportArguments(\n",
    "    input_file_list=[\"catalog_b.csv\"],\n",
    "    output_path=\"import_pipeline\",\n",
    "    sort_columns=\"survey_id\",\n",
    "    constant_healpix_order=4,\n",
    "    file_reader=\"csv\",\n",
    "    output_artifact_name=\"catalog_b\",\n",
    "    tmp_dir=tmp_dir,\n",
    ")\n",
    "\n",
    "with Client(n_workers=1, threads_per_worker=1, local_directory=tmp_dir) as client:\n",
    "    runner.pipeline_with_client(catalog_a_args, client)\n",
    "    runner.pipeline_with_client(catalog_b_args, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipscatenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
